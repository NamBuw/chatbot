import sounddevice as sd
import numpy as np
from silero_vad import load_silero_vad
import whisper
import torch
import queue
import time
import sys
import select
import noisereduce as nr
import os
import json
import google.generativeai as genai
import re
from datetime import datetime
import threading
import unicodedata
# ==================== CONFIGURATION ====================

API_KEY = "YOUR_API_KEY_HERE"
genai.configure(api_key=API_KEY)

USER_INFO_FILE = 'user_info.json'
TOPICS_DIR = 'topics'
file_lock = threading.Lock()

# ==================== ENHANCED TOPICS CONFIGURATION ====================

TOPICS = {
    'que_huong': {
        'name': 'ğŸ  QuÃª hÆ°Æ¡ng vÃ  hoÃ i niá»‡m',
        'description': 'KÃ½ á»©c vá» quÃª nhÃ , mÃ³n Äƒn truyá»n thá»‘ng, ca dao tá»¥c ngá»¯, Ã¢m nháº¡c quÃª hÆ°Æ¡ng',
        'folder': 'que_huong',
        'emoji': 'ğŸ ',
        'keywords': ['quÃª', 'nhÃ ', 'cÆ¡m', 'phá»Ÿ', 'lÃ ng', 'sÃ´ng', 'cÃ¢y', 'hoÃ i niá»‡m'],
        'greeting': 'ChÃ o bÃ¡c! ChÃ¡u ráº¥t vui Ä‘Æ°á»£c nghe bÃ¡c ká»ƒ vá» quÃª hÆ°Æ¡ng. BÃ¡c muá»‘n chia sáº» gÃ¬ vá» quÃª nhÃ ?'
    },
    'gia_dinh': {
        'name': 'ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Gia Ä‘Ã¬nh',
        'description': 'LiÃªn láº¡c vá»›i ngÆ°á»i thÃ¢n, truyá»n dáº¡y vÄƒn hÃ³a cho con chÃ¡u, ká»ƒ chuyá»‡n gia Ä‘Ã¬nh',
        'folder': 'gia_dinh',
        'emoji': 'ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦',
        'keywords': ['con', 'chÃ¡u', 'vá»£', 'chá»“ng', 'anh em', 'gia Ä‘Ã¬nh', 'há»p máº·t'],
        'greeting': 'ChÃ o bÃ¡c! ChÃ¡u thÃ­ch nghe bÃ¡c ká»ƒ vá» gia Ä‘Ã¬nh. Gia Ä‘Ã¬nh bÃ¡c cÃ³ gÃ¬ vui khÃ´ng?'
    },
    'suc_khoe': {
        'name': 'ğŸ’Š Sá»©c khá»e',
        'description': 'Thuá»‘c nam, cháº¿ Ä‘á»™ Äƒn uá»‘ng, táº­p thá»ƒ dá»¥c cho ngÆ°á»i cao tuá»•i',
        'folder': 'suc_khoe',
        'emoji': 'ğŸ’Š',
        'keywords': ['khá»e', 'thuá»‘c', 'bá»‡nh', 'táº­p', 'Äƒn', 'uá»‘ng', 'ngá»§'],
        'greeting': 'ChÃ o bÃ¡c! Sá»©c khá»e lÃ  vÃ ng Ä‘Ãºng khÃ´ng? BÃ¡c cÃ³ muá»‘n tÃ¢m sá»± vá» sá»©c khá»e khÃ´ng?'
    },
    'lich_su': {
        'name': 'ğŸ“š Lá»‹ch sá»­',
        'description': 'CÃ¡c triá»u Ä‘áº¡i, khÃ¡ng chiáº¿n, nhÃ¢n váº­t lá»‹ch sá»­, sá»± kiá»‡n Ä‘Ã£ tráº£i qua',
        'folder': 'lich_su',
        'emoji': 'ğŸ“š',
        'keywords': ['lá»‹ch sá»­', 'chiáº¿n tranh', 'vua', 'anh hÃ¹ng', 'cÃ¡ch máº¡ng'],
        'greeting': 'ChÃ o bÃ¡c! ChÃ¡u muá»‘n nghe bÃ¡c ká»ƒ vá» nhá»¯ng cÃ¢u chuyá»‡n lá»‹ch sá»­ thÃº vá»‹.'
    },
    'tam_linh': {
        'name': 'ğŸ™ TÃ¢m linh',
        'description': 'Pháº­t giÃ¡o, thá» cÃºng tá»• tiÃªn, lá»… há»™i truyá»n thá»‘ng, phong thá»§y',
        'folder': 'tam_linh',
        'emoji': 'ğŸ™',
        'keywords': ['pháº­t', 'cÃºng', 'tá»• tiÃªn', 'chÃ¹a', 'lá»…', 'phong thá»§y'],
        'greeting': 'ChÃ o bÃ¡c! ChÃ¡u sáºµn sÃ ng tÃ¢m sá»± vá»›i bÃ¡c vá» tÃ¢m linh vÃ  tÃ­n ngÆ°á»¡ng.'
    }
}

# ==================== HALLUCINATION FILTER ====================

class HallucinationFilter:
    """Lá»c hallucination cho Whisper STT"""
    
    def __init__(self):
        # Vietnamese hallucination patterns
        # CÃ¢u spam cáº§n match chÃ­nh xÃ¡c (exact match)
        self.exact_hallucinations = [
        "háº¹n gáº·p láº¡i cÃ¡c báº¡n trong nhá»¯ng video tiáº¿p theo.",
        "cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi vÃ  háº¹n gáº·p láº¡i.",
        "hÃ£y Ä‘Äƒng kÃ½ kÃªnh Ä‘á»ƒ khÃ´ng bá» lá»¡ video má»›i.",
        "hÃ£y like vÃ  subscribe Ä‘á»ƒ á»§ng há»™ kÃªnh.",
        "hÃ£y Ä‘Äƒng kÃ½ kÃªnh Ä‘á»ƒ á»§ng há»™",
        "hÃ£y Ä‘Äƒng kÃ½ kÃªnh Ä‘á»ƒ xem thÃªm nhiá»u video hay",
]

# CÃ¡c cá»¥m spam ngáº¯n, chá»‰ cáº§n xuáº¥t hiá»‡n trong cÃ¢u (substring match)
        self.partial_hallucinations = [
            "Ä‘Äƒng kÃ½", "Ä‘Äƒng kÃ½ kÃªnh", "subscribe", "like vÃ  subscribe",
            "lala", "lalala", "ghiá»n mÃ¬ gÃµ", "Æ¡ Æ¡ Æ¡", "Ã  Ã  Ã ", "á» á» á»",
            "á»« á»« á»«", "á»­ á»­ á»­", "e e e", "i i i", "u u u", "o o o",
]
        
        # English hallucination patterns
        self.english_patterns = [
            "thank you for watching", "thanks for watching", "like and subscribe",
            "subscribe to", "www.", "http", ".com", "please subscribe",
            "hit the bell", "notification bell"
        ]
        
        # Music/sound patterns
        self.music_patterns = [
            "â™ª", "â™«", "music", "Ã¢m nháº¡c", "nháº¡c ná»n",
            "[Ã¢m nháº¡c]", "[music]", "(music)", "(Ã¢m nháº¡c)"
        ]
        
        # Quality thresholds
        self.min_length = 3
        self.max_length = 200
        self.min_confidence = 0.00


    def is_hallucination(self, text, confidence=None):
        """Kiá»ƒm tra xem text cÃ³ pháº£i lÃ  hallucination hay khÃ´ng"""
        text_clean = text.strip().lower()

        # Check length
        if len(text_clean) < self.min_length or len(text_clean) > self.max_length:
            return True

        # Check confidence if provided
        if confidence is not None and confidence < self.min_confidence:
            return True

        # Check exact match hallucinations
        if text_clean in self.exact_hallucinations:
            return True

        # Check partial (substring) hallucinations
        for pattern in self.partial_hallucinations:
            if pattern in text_clean:
                return True

        # Check English hallucinations
        for pattern in self.english_patterns:
             if pattern in text_clean:
                return True

        # Check music patterns
        for pattern in self.music_patterns:
             if pattern in text_clean:
                return True

        # Check repetitive patterns
        if self._is_repetitive(text_clean):
            return True

         # Check if mostly non-alphabetic
        if self._is_mostly_symbols(text_clean):
            return True

        return False

    def _is_repetitive(self, text):
        """Kiá»ƒm tra pattern láº·p láº¡i"""
        words = text.split()
        if len(words) < 3:
            return False
            
        word_count = {}
        for word in words:
            word_count[word] = word_count.get(word, 0) + 1
            if word_count[word] >= 3:
                return True
        return False

    def _is_mostly_symbols(self, text):
        """Kiá»ƒm tra xem cÃ³ pháº£i chá»§ yáº¿u lÃ  kÃ½ tá»± Ä‘áº·c biá»‡t khÃ´ng"""
        if len(text) == 0:
            return True
        alpha_count = sum(1 for c in text if c.isalpha())
        return alpha_count / len(text) < 0.5

    def filter_text(self, text, confidence=None):
        """Lá»c text, tráº£ vá» text clean hoáº·c empty string"""
        if self.is_hallucination(text, confidence):
            return ""
        
        # Clean up text
        text_clean = text.strip()
        text_clean = re.sub(r'\s+', ' ', text_clean)
        return text_clean

# ==================== ADVANCED EMOTION DETECTION ====================

def detect_emotion_and_optimize_response(user_message):
    """PhÃ¢n tÃ­ch cáº£m xÃºc vÃ  Ä‘Æ°a ra gá»£i Ã½ pháº£n há»“i"""
    emotion_keywords = {
        'buá»“n': ['buá»“n', 'khÃ³c', 'cÃ´ Ä‘Æ¡n', 'má»™t mÃ¬nh', 'chÃ¡n náº£n', 'tá»§i thÃ¢n', 'u uáº¥t'],
        'nhá»›_quÃª': ['nhá»›', 'quÃª', 'xa nhÃ ', 'nÆ°á»›c ngoÃ i', 'hoÃ i niá»‡m', 'hÆ°Æ¡ng', 'lÃ ng'],
        'lo_láº¯ng': ['lo', 'sá»£', 'bÄƒn khoÄƒn', 'khÃ´ng biáº¿t', 'tháº¿ nÃ o', 'lÃ m sao', 'tÃ¬m Ä‘Ã¢u'],
        'vui': ['vui', 'háº¡nh phÃºc', 'tá»‘t', 'khá»e', 'hÃ i lÃ²ng', 'sung sÆ°á»›ng', 'pháº¥n khÃ­ch'],
        'bá»‡nh_táº­t': ['Ä‘au', 'á»‘m', 'bá»‡nh', 'má»‡t', 'yáº¿u', 'thuá»‘c', 'khÃ³ chá»‹u'],
        'gia_Ä‘Ã¬nh': ['con', 'chÃ¡u', 'vá»£', 'chá»“ng', 'anh em', 'há» hÃ ng', 'thÄƒm']
    }
    
    detected_emotions = []
    message_lower = user_message.lower()
    
    for emotion, keywords in emotion_keywords.items():
        if any(keyword in message_lower for keyword in keywords):
            detected_emotions.append(emotion)
    
    # Táº¡o response optimization hint
    optimization_hint = ""
    if 'buá»“n' in detected_emotions:
        optimization_hint += """
PHÃT HIá»†N Cáº¢M XÃšC BUá»’N - ÃP Dá»¤NG CHIáº¾N LÆ¯á»¢C AN á»¦I:
â€¢ Báº¯t Ä‘áº§u báº±ng viá»‡c thá»«a nháº­n cáº£m xÃºc: "ChÃ¡u hiá»ƒu bÃ¡c Ä‘ang buá»“n..."
â€¢ Äá»“ng hÃ nh: "BÃ¡c khÃ´ng má»™t mÃ¬nh Ä‘Ã¢u, cÃ³ chÃ¡u á»Ÿ Ä‘Ã¢y"
â€¢ Chuyá»ƒn hÆ°á»›ng nháº¹ nhÃ ng vá» Ä‘iá»u tÃ­ch cá»±c
â€¢ TRÃNH: KhuyÃªn giáº£i ngay, bá» qua cáº£m xÃºc
"""
    
    if 'nhá»›_quÃª' in detected_emotions:
        optimization_hint += """
PHÃT HIá»†N TÃŒNH Cáº¢M NHá»š QUÃŠ - ÃP Dá»¤NG CHIáº¾N LÆ¯á»¢C HOÃ€I NIá»†M:
â€¢ Chia sáº» cáº£m xÃºc: "Xa quÃª lÃ²ng nao nao, chÃ¡u hiá»ƒu láº¯m..."
â€¢ Gá»£i má»Ÿ kÃ½ á»©c: "MÃ³n gÃ¬ á»Ÿ quÃª bÃ¡c thÃ­ch nháº¥t?"
â€¢ Káº¿t ná»‘i vÄƒn hÃ³a: "MÃ¬nh cÃ¹ng tÃ¬m cÃ¡ch lÃ m mÃ³n Ä‘Ã³ á»Ÿ Ä‘Ã¢y"
â€¢ TRÃNH: NÃ³i vá» tÆ°Æ¡ng lai, bá» qua ná»—i nhá»›
"""
    
    return detected_emotions, optimization_hint

# ==================== DIALECT SUPPORT ====================

def get_dialect_style(hometown):
    """XÃ¡c Ä‘á»‹nh giá»ng Ä‘á»‹a phÆ°Æ¡ng vá»›i Chain of Thought vÃ  Few-shot Prompting"""
    # Mapping cÃ¡c tá»‰nh vá» Ä‘áº¡i diá»‡n
    province_mapping = {
        # Miá»n Báº¯c
        "HÃ  Ná»™i": "HÃ  Ná»™i", "HÃ  TÃ¢y": "HÃ  Ná»™i", "Báº¯c Ninh": "HÃ  Ná»™i",
        "Nam Äá»‹nh": "Nam Äá»‹nh", "ThÃ¡i BÃ¬nh": "Nam Äá»‹nh", "HÃ  Nam": "Nam Äá»‹nh",
        
        # Miá»n Trung
        "Huáº¿": "Huáº¿", "Thá»«a ThiÃªn Huáº¿": "Huáº¿", "Quáº£ng Trá»‹": "Huáº¿",
        "Nghá»‡ An": "Nghá»‡ An", "HÃ  TÄ©nh": "Nghá»‡ An", "Thanh HÃ³a": "Nghá»‡ An",
        
        # Miá»n Nam
        "TP.HCM": "TP.HCM", "Há»“ ChÃ­ Minh": "TP.HCM", "SÃ i GÃ²n": "TP.HCM",
        "Cáº§n ThÆ¡": "Cáº§n ThÆ¡", "An Giang": "Cáº§n ThÆ¡", "KiÃªn Giang": "Cáº§n ThÆ¡"
    }
    
    representative = province_mapping.get(hometown, "HÃ  Ná»™i")
    
    dialect_examples = {
        "HÃ  Ná»™i": "Giá»ng lá»‹ch sá»±, trang trá»ng, dÃ¹ng 'áº¡', 'thÆ°a', 'dáº¡'",
        "Nam Äá»‹nh": "ChÃ¢n cháº¥t, má»™c máº¡c, dÃ¹ng 'nhá»‰', 'Ä‘Ã³', 'nÃ y'",
        "Huáº¿": "Nháº¹ nhÃ ng, ngá»t ngÃ o, dÃ¹ng 'mÃ¬nh', 'rá»©a', 'nÃ¬'", 
        "Nghá»‡ An": "Giá»ng 'gi' thÃ nh 'di', 'r' thÃ nh 'z', chÃ¢n cháº¥t",
        "TP.HCM": "Thoáº£i mÃ¡i, phÃ³ng khoÃ¡ng, dÃ¹ng 'nhÃ©', 'nha', 'dzáº­y'",
        "Cáº§n ThÆ¡": "Äáº­m cháº¥t miá»n TÃ¢y, dÃ¹ng 'máº§y', 'tui', 'dzáº­y'"
    }
    
    return f"""
GIá»ŒNG {representative.upper()}:
Äáº·c Ä‘iá»ƒm: {dialect_examples.get(representative, 'Giá»ng chung cá»§a ngÆ°á»i Viá»‡t')}

HÆ¯á»šNG DáºªN ÃP Dá»¤NG:
- Sá»­ dá»¥ng tá»« ngá»¯ Ä‘áº·c trÆ°ng má»™t cÃ¡ch Tá»° NHIÃŠN
- Giá»¯ giá»ng Ä‘iá»‡u gáº§n gÅ©i, thÃ¢n máº­t
- Lá»“ng ghÃ©p vÄƒn hÃ³a, mÃ³n Äƒn Ä‘á»‹a phÆ°Æ¡ng
- Äáº£m báº£o giá»ng nÃ³i tá»± nhiÃªn, phÃ¹ há»£p ngÆ°á»i cao tuá»•i
"""

# ==================== FILE MANAGEMENT ====================

def ensure_topic_folders():
    """Táº¡o cÃ¡c thÆ° má»¥c chá»§ Ä‘á» náº¿u chÆ°a cÃ³"""
    if not os.path.exists(TOPICS_DIR):
        os.makedirs(TOPICS_DIR)
        print(f"ÄÃ£ táº¡o thÆ° má»¥c chÃ­nh: {TOPICS_DIR}")
    
    for topic_key, topic_info in TOPICS.items():
        topic_path = os.path.join(TOPICS_DIR, topic_info['folder'])
        if not os.path.exists(topic_path):
            os.makedirs(topic_path)
            print(f"ÄÃ£ táº¡o thÆ° má»¥c: {topic_path}")

def get_topic_file_path(topic_key, file_type):
    """Láº¥y Ä‘Æ°á»ng dáº«n file theo chá»§ Ä‘á»"""
    if topic_key not in TOPICS:
        raise ValueError(f"Chá»§ Ä‘á» khÃ´ng há»£p lá»‡: {topic_key}")
    
    topic_folder = TOPICS[topic_key]['folder']
    file_names = {
        'history': 'chat_history.json',
        'context': 'chat_context.json',
        'summary': 'chat_summary.json',
        'backup': 'full_conversation_backup.json'
    }
    
    if file_type not in file_names:
        raise ValueError(f"Loáº¡i file khÃ´ng há»£p lá»‡: {file_type}")
    
    return os.path.join(TOPICS_DIR, topic_folder, file_names[file_type])

def load_user_info():
    """
    Äá»c thÃ´ng tin ngÆ°á»i dÃ¹ng tá»« file JSON vÃ  luÃ´n reload tá»« file.
    Náº¿u file khÃ´ng tá»“n táº¡i, táº¡o file máº«u vá»›i thÃ´ng tin máº·c Ä‘á»‹nh.
    """
    try:
        # # In ra working directory Ä‘á»ƒ debug (tuá»³ chá»n)
        # print("Current working dir:", os.getcwd())
        
        if os.path.exists(USER_INFO_FILE):
            with open(USER_INFO_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # print("âœ… Loaded user_info:", data)
                return data
        
        # Náº¿u file chÆ°a tá»“n táº¡i, táº¡o file máº«u
        default_info = {
            "name": "BÃ¡c TÃ¢m",
            "age": 70,
            "gender": "Nam",
            "hometown": "Nam Äá»‹nh",
            "location": "HÃ  Ná»™i",
            "occupation": "GiÃ¡o viÃªn vá» hÆ°u",
            "family": "CÃ³ vá»£, 2 con, 3 chÃ¡u",
            "health": "Khá»e máº¡nh",
            "call_style": "bÃ¡c"
        }
        with open(USER_INFO_FILE, 'w', encoding='utf-8') as f:
            json.dump(default_info, f, ensure_ascii=False, indent=2)
        print(f"âš ï¸ File {USER_INFO_FILE} khÃ´ng tá»“n táº¡i. ÄÃ£ táº¡o file máº«u vá»›i thÃ´ng tin máº·c Ä‘á»‹nh.")
        return default_info
    
    except Exception as e:
        # Báº¯t má»i lá»—i Ä‘á»c/ghi vÃ  tráº£ vá» dict rá»—ng
        print(f"âŒ Error loading {USER_INFO_FILE}: {e}")
        return {}

# ==================== ADVANCED PROMPTING SYSTEM ====================

def get_enhanced_system_prompt(topic_key, user_input=None, user_info=None):
    """Táº¡o prompt nÃ¢ng cao vá»›i Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng tá»« GitHub repo"""
    # LUÃ”N reload user_info má»›i nháº¥t tá»« file
    user_info = load_user_info()
    
    prompt_parts = []
    
    # Pháº§n 1: Vai trÃ² vÃ  nguyÃªn táº¯c cÆ¡ báº£n
    prompt_parts.append("""
Báº¡n lÃ  má»™t ngÆ°á»i báº¡n thÃ¢n thiáº¿t, luÃ´n láº¯ng nghe, chia sáº» vÃ  tÃ¢m sá»± vá»›i ngÆ°á»i lá»›n tuá»•i Viá»‡t Nam.
HÃ£y trÃ² chuyá»‡n nhÆ° má»™t ngÆ°á»i báº¡n Ä‘á»“ng hÃ nh, khÃ´ng pháº£i chuyÃªn gia hay trá»£ lÃ½ AI.

NGUYÃŠN Táº®C VÃ€NG:
- TRáº¢ Lá»œI NGáº®N Gá»ŒN: Tá»I ÄA 4-5 CÃ‚U, trÃ¡nh dÃ i dÃ²ng
- SÃNG Táº O TRONG CÃCH TRáº¢ Lá»œI: KhÃ´ng dÃ¹ng tá»« ngá»¯ mÃ¡y mÃ³c, trÃ¡nh láº·p tá»«
- LuÃ´n láº¯ng nghe, Ä‘á»“ng cáº£m, chia sáº» cáº£m xÃºc, Ä‘á»™ng viÃªn nháº¹ nhÃ ng
- Sá»­ dá»¥ng giá»ng Ä‘iá»‡u tá»± nhiÃªn, gáº§n gÅ©i, thÃ¢n máº­t
- KhÃ´ng dÃ¹ng markdown, khÃ´ng in Ä‘áº­m, khÃ´ng kÃ½ tá»± Ä‘áº·c biá»‡t
- NÃ“I NHÆ¯ NGÆ¯á»œI THáº¬T: CÃ¢u chuyá»‡n tá»± nhiÃªn nhÆ° nÃ³i chuyá»‡n hÃ ng ngÃ y
""")
    
    # Pháº§n 2: ThÃ´ng tin cÃ¡ nhÃ¢n
    if user_info:
        call_style = user_info.get('call_style', 'bÃ¡c')
        prompt_parts.append(f"\nQUAN TRá»ŒNG: LuÃ´n gá»i ngÆ°á»i dÃ¹ng lÃ  '{call_style}' trong má»i cÃ¢u tráº£ lá»i.\n")
        
        # ThÃªm thÃ´ng tin cÃ¡ nhÃ¢n
        personal_info = []
        if user_info.get('name'): personal_info.append(f"TÃªn: {user_info['name']}")
        if user_info.get('age'): personal_info.append(f"Tuá»•i: {user_info['age']}")
        if user_info.get('hometown'): personal_info.append(f"QuÃª quÃ¡n: {user_info['hometown']}")
        if user_info.get('location'): personal_info.append(f"NÆ¡i á»Ÿ: {user_info['location']}")
        if user_info.get('occupation'): personal_info.append(f"Nghá» nghiá»‡p: {user_info['occupation']}")
        
        if personal_info:
            prompt_parts.append("THÃ”NG TIN CÃ NHÃ‚N Cáº¦N Sá»¬ Dá»¤NG: " + ", ".join(personal_info) + "\n")
        
        # Giá»ng Ä‘á»‹a phÆ°Æ¡ng
        if user_info.get('hometown'):
            dialect_style = get_dialect_style(user_info['hometown'])
            prompt_parts.append(f"\nGIá»ŒNG Äá»ŠA PHÆ¯Æ NG: {dialect_style}\n")
    
    # Pháº§n 3: Chá»§ Ä‘á» cá»¥ thá»ƒ
    topic_prompts = {
        'que_huong': """
Báº N LÃ€ CHUYÃŠN GIA Vá»€ QUÃŠ HÆ¯Æ NG VÃ€ HOÃ€I NIá»†M:
- Chia sáº» vá» mÃ³n Äƒn quÃª hÆ°Æ¡ng, cÃ¡ch náº¥u truyá»n thá»‘ng
- Ká»ƒ vá» phong cáº£nh, con ngÆ°á»i, lÃ ng xÃ³m quÃª nhÃ 
- Nhá»› vá» ca dao, tá»¥c ngá»¯, truyá»‡n cá»• tÃ­ch
- MÃ´ táº£ lá»… há»™i, táº¿t cá»• truyá»n, phong tá»¥c táº­p quÃ¡n
""",
        'gia_dinh': """
Báº N LÃ€ CHUYÃŠN GIA Vá»€ GIA ÄÃŒNH:
- ÄÆ°a ra cÃ¡ch giá»¯ liÃªn láº¡c vá»›i ngÆ°á»i thÃ¢n
- HÆ°á»›ng dáº«n truyá»n dáº¡y tiáº¿ng Viá»‡t, vÄƒn hÃ³a cho con chÃ¡u
- Ká»ƒ chuyá»‡n vá» gia Ä‘Ã¬nh, tá»• tiÃªn vá»›i giá»ng Ä‘iá»‡u áº¥m Ã¡p
- Há»— trá»£ giÃ¡o dá»¥c con chÃ¡u vá» vÄƒn hÃ³a Viá»‡t
""",
        'suc_khoe': """
Báº N LÃ€ CHUYÃŠN GIA Vá»€ Sá»¨C KHá»E:
- Giá»›i thiá»‡u thuá»‘c nam, bÃ i thuá»‘c dÃ¢n gian
- Äá» xuáº¥t cháº¿ Ä‘á»™ Äƒn uá»‘ng bá»• dÆ°á»¡ng cho ngÆ°á»i cao tuá»•i
- Gá»£i Ã½ bÃ i táº­p thá»ƒ dá»¥c phÃ¹ há»£p (thÃ¡i cá»±c quyá»n, yoga)
- Chia sáº» cÃ¡ch phÃ²ng ngá»«a bá»‡nh táº­t
""",
        'lich_su': """
Báº N LÃ€ CHUYÃŠN GIA Vá»€ Lá»ŠCH Sá»¬ VIá»†T NAM:
- Ká»ƒ vá» cÃ¡c triá»u Ä‘áº¡i, vua chÃºa ná»•i tiáº¿ng
- MÃ´ táº£ cÃ¡c cuá»™c khÃ¡ng chiáº¿n chá»‘ng PhÃ¡p, chá»‘ng Má»¹
- Chia sáº» vá» nhÃ¢n váº­t lá»‹ch sá»­ vá»›i gÃ³c nhÃ¬n gáº§n gÅ©i
- Truyá»n Ä‘áº¡t bÃ i há»c lá»‹ch sá»­ cho tháº¿ há»‡ tráº»
""",
        'tam_linh': """
Báº N LÃ€ CHUYÃŠN GIA Vá»€ VÄ‚N HÃ“A TÃ‚M LINH:
- Giáº£i thÃ­ch vá» Pháº­t giÃ¡o, tÃ­n ngÆ°á»¡ng Viá»‡t Nam
- HÆ°á»›ng dáº«n cÃ¡ch thá» cÃºng tá»• tiÃªn á»Ÿ nÆ°á»›c ngoÃ i
- MÃ´ táº£ lá»… há»™i, táº¿t cá»• truyá»n vá»›i Ã½ nghÄ©a tÃ¢m linh
- Chia sáº» triáº¿t lÃ½ sá»‘ng, tu dÆ°á»¡ng Ä‘áº¡o Ä‘á»©c
"""
    }
    
    if topic_key in topic_prompts:
        prompt_parts.append(topic_prompts[topic_key])
    
    return '\n'.join(prompt_parts)

# ==================== CONVERSATION MANAGEMENT ====================

def load_chat_history(topic_key):
    """Load lá»‹ch sá»­ chat theo chá»§ Ä‘á»"""
    try:
        file_path = get_topic_file_path(topic_key, 'history')
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('messages', [])
        return []
    except Exception as e:
        print(f"Lá»—i Ä‘á»c file lá»‹ch sá»­ {topic_key}: {e}")
        return []

def save_chat_history(topic_key, messages):
    """LÆ°u lá»‹ch sá»­ chat theo chá»§ Ä‘á»"""
    try:
        with file_lock:
            file_path = get_topic_file_path(topic_key, 'history')
            chat_data = {
                'topic': topic_key,
                'topic_name': TOPICS[topic_key]['name'],
                'created_at': datetime.now().isoformat(),
                'last_updated': datetime.now().isoformat(),
                'total_messages': len(messages),
                'messages': messages
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(chat_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Lá»—i ghi file lá»‹ch sá»­ {topic_key}: {e}")

def add_message_to_history(topic_key, user_message, bot_response):
    """ThÃªm tin nháº¯n vÃ o lá»‹ch sá»­"""
    new_message = {
        'timestamp': datetime.now().isoformat(),
        'user': user_message,
        'bot': bot_response,
        'emotions_detected': detect_emotion_and_optimize_response(user_message)[0]
    }
    
    messages = load_chat_history(topic_key)
    messages.append(new_message)
    save_chat_history(topic_key, messages)

# ==================== ENHANCED LLM CLASS ====================

class EnhancedVietnameseLLM:
    """Enhanced Vietnamese LLM with full features from GitHub repo"""
    
    def __init__(self, api_key=None, default_topic='que_huong'):
        self.api_key = api_key or API_KEY
        try:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel("gemini-2.5-flash")
        except Exception as e:
            print(f"âŒ Lá»—i cáº¥u hÃ¬nh Gemini API: {e}")
            self.model = None
            return
        
        self.current_topic = default_topic
        self.chat_session = None
        
        # Initialize session
        self._initialize_session(default_topic)
    
    def _initialize_session(self, topic):
        """Khá»Ÿi táº¡o chat session vá»›i prompt nÃ¢ng cao - LUÃ”N reload user_info"""
        if not self.model:
            print("âŒ Model chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o")
            return
        
        try:
            self.current_topic = topic
            
            # LUÃ”N táº£i láº¡i user_info má»›i nháº¥t tá»« file
            current_user_info = load_user_info()
            
            # Táº¡o system prompt nÃ¢ng cao vá»›i user_info má»›i nháº¥t
            system_prompt = get_enhanced_system_prompt(topic, user_info=current_user_info)
            
            # Táº¡o lá»i chÃ o thÃ¢n thiá»‡n
            topic_info = TOPICS[topic]
            greeting = topic_info['greeting']
            
            # Khá»Ÿi táº¡o chat session
            self.chat_session = self.model.start_chat(
                history=[
                    {
                        "role": "user",
                        "parts": [system_prompt]
                    },
                    {
                        "role": "model", 
                        "parts": [greeting]
                    }
                ]
            )
            
            # print(f"ğŸ¤– Khá»Ÿi táº¡o session cho chá»§ Ä‘á»: {topic}")
            # print(f"ğŸ¤– Bot: {greeting}")
            
        except Exception as e:
            print(f"âŒ Lá»—i khá»Ÿi táº¡o LLM session: {e}")
            self.chat_session = None
    
    def update_user_info(self):
        self._initialize_session(self.current_topic)
    
    def chat(self, text, topic_key=None):
        """Chat vá»›i LLM vá»›i emotion detection vÃ  user_info update"""
        if not self.chat_session:
            return "Xin lá»—i bÃ¡c, chÃ¡u gáº·p chÃºt váº¥n Ä‘á» ká»¹ thuáº­t. Vui lÃ²ng kiá»ƒm tra API key."
        
        # Chuyá»ƒn topic náº¿u cáº§n
        if topic_key and topic_key != self.current_topic:
            self._initialize_session(topic_key)
        
        # LuÃ´n reload user_info trÆ°á»›c khi chat Ä‘á»ƒ Ä‘áº£m báº£o cáº­p nháº­t
        self.update_user_info()
        
        try:
            # PhÃ¢n tÃ­ch cáº£m xÃºc
            detected_emotions, optimization_hint = detect_emotion_and_optimize_response(text)
            
            # ThÃªm optimization hint náº¿u cÃ³
            enhanced_message = text
            if optimization_hint:
                enhanced_message = f"{optimization_hint}\n\nTin nháº¯n tá»« ngÆ°á»i dÃ¹ng: {text}"
            
            # Táº¡o response
            response = self.chat_session.send_message(enhanced_message, stream=False)
            
            if response and response.text:
                response_text = response.text.strip()
                
                # LÃ m sáº¡ch markdown formatting
                response_text = re.sub(r'\*{1,3}(.*?)\*{1,3}', r'\1', response_text)
                response_text = re.sub(r'`{1,3}(.*?)`{1,3}', r'\1', response_text)
                
                # LÆ°u vÃ o lá»‹ch sá»­
                if topic_key:
                    add_message_to_history(topic_key, text, response_text)
                
                return response_text
            else:
                return "BÃ¡c Æ¡i, chÃ¡u khÃ´ng nghe rÃµ. BÃ¡c nÃ³i láº¡i Ä‘Æ°á»£c khÃ´ng?"
                
        except Exception as e:
            print(f"âŒ Lá»—i LLM: {e}")
            return "Xin lá»—i bÃ¡c, chÃ¡u Ä‘ang báº­n má»™t tÃ­. BÃ¡c Ä‘á»£i chÃ¡u má»™t chÃºt nhÃ©."

# ==================== SPEECH PROCESSING WITH TIMING ====================

def process_audio_with_llm(frames, stt_model, llm, hallucination_filter, device, sample_rate, topic_key='que_huong'):
    """Xá»­ lÃ½ audio vá»›i LLM integration vÃ  Ä‘o thá»i gian"""
    try:
        # Báº¯t Ä‘áº§u Ä‘o tá»•ng thá»i gian
        start_total_time = time.time()
        
        # Concatenate and denoise audio
        audio_np = np.concatenate(frames)
        
        with np.errstate(divide='ignore', invalid='ignore'):
            audio_denoised = nr.reduce_noise(y=audio_np.astype(np.float32), sr=sample_rate)
        
        # STT vá»›i Ä‘o thá»i gian
        print("ğŸ”„ Äang nháº­n dáº¡ng tiáº¿ng nÃ³i...")
        start_stt_time = time.time()
        result = stt_model.transcribe(audio_denoised, language='vi', fp16=(device == "cuda"))
        end_stt_time = time.time()
        stt_processing_time = end_stt_time - start_stt_time
        
        raw_text = result["text"].strip()
        confidence = result.get("avg_logprob", 0)
        
        # print(f"ğŸ—£ï¸ Raw STT: '{raw_text}' (confidence: {confidence:.3f})")
        # print(f"â±ï¸ Thá»i gian STT: {stt_processing_time:.3f} giÃ¢y")
        
        # Apply hallucination filter
        filtered_text = hallucination_filter.filter_text(raw_text, confidence)
        
        if not filtered_text:
            print("ğŸ” Filtered as hallucination")
            return None
        
        # print(f"âœ… Filtered text: '{filtered_text}'")
        print(f"ğŸ‘¤ Báº¡n: {filtered_text}")
        
        # LLM Response vá»›i Ä‘o thá»i gian
        # print("ğŸ”„ Äang suy nghÄ©...")
        start_llm_time = time.time()
        bot_response = llm.chat(filtered_text, topic_key)
        end_llm_time = time.time()
        llm_processing_time = end_llm_time - start_llm_time
        
        # TÃ­nh tá»•ng thá»i gian
        end_total_time = time.time()
        total_processing_time = end_total_time - start_total_time
        
        print(f"ğŸ¤– Bot: {bot_response}")
        # print(f"â±ï¸ Thá»i gian LLM: {llm_processing_time:.3f} giÃ¢y")
        # print(f"â±ï¸ Tá»•ng thá»i gian xá»­ lÃ½: {total_processing_time:.3f} giÃ¢y")
        print(f"ğŸ“Š Tá»•ng thá»i gian xá»­ lÃ½: STT({stt_processing_time:.3f}s) + LLM({llm_processing_time:.3f}s) = Total({total_processing_time:.3f}s)")
        
        return {"user": filtered_text, "bot": bot_response}
        
    except Exception as e:
        print(f"âŒ Lá»—i xá»­ lÃ½ audio: {e}")
        return None

# ==================== MAIN TERMINAL MODE ====================

def run_terminal_mode():
    """Cháº¡y cháº¿ Ä‘á»™ terminal vá»›i Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng"""
    # Äáº£m báº£o cÃ¡c thÆ° má»¥c tá»“n táº¡i
    ensure_topic_folders()
    
    print("ğŸ”„ Äang táº£i models...")
    
    # Load models
    vad_model = load_silero_vad()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    stt_model = whisper.load_model("large-v3", device=device)
    
    # Initialize components
    print("ğŸ”„ Äang khá»Ÿi táº¡o Vietnamese LLM...")
    llm = EnhancedVietnameseLLM()
    if not llm.model:
        print("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o LLM. Vui lÃ²ng kiá»ƒm tra API key.")
        return
    
    print("ğŸ”„ Äang khá»Ÿi táº¡o Hallucination Filter...")
    hallucination_filter = HallucinationFilter()
    
    print("âœ… Táº¥t cáº£ components Ä‘Ã£ sáºµn sÃ ng!")
    
    # Audio settings
    sample_rate = 16000
    block_duration = 0.3
    block_size = int(sample_rate * block_duration)
    silence_threshold = 0.7
    q = queue.Queue()
    
    # Statistics
    stats = {
        'total_transcriptions': 0,
        'filtered_hallucinations': 0,
        'successful_responses': 0
    }
    
    def audio_callback(indata, frames, time_info, status):
        """Callback thu Ã¢m"""
        q.put(indata.copy())
    
    def is_speech_block(audio_block, vad_model, sample_rate, chunk_size=512):
        """Kiá»ƒm tra cÃ³ tiáº¿ng nÃ³i khÃ´ng"""
        for start in range(0, len(audio_block), chunk_size):
            chunk = audio_block[start:start+chunk_size]
            if len(chunk) < chunk_size:
                break
            tensor_chunk = torch.from_numpy(chunk).float()
            prob = vad_model(tensor_chunk, sample_rate)
            if prob.item() > 0.5:
                return True
        return False
    
    # Chá»n chá»§ Ä‘á»
    print("\n" + "="*70)
    print("        ğŸ¤ VIETNAMESE COMPANION CHATBOT - TERMINAL MODE")
    print("="*70)
    print("Chá»n chá»§ Ä‘á» tÃ¢m sá»±:")
    for i, (key, info) in enumerate(TOPICS.items(), 1):
        print(f"{i}. {info['name']}: {info['description']}")
    
    while True:
        try:
            choice = input("\nNháº­p sá»‘ thá»© tá»± chá»§ Ä‘á» (1-5): ").strip()
            topic_keys = list(TOPICS.keys())
            if choice.isdigit() and 1 <= int(choice) <= len(topic_keys):
                selected_topic = topic_keys[int(choice) - 1]
                llm._initialize_session(selected_topic)
                break
            else:
                print("Vui lÃ²ng nháº­p sá»‘ tá»« 1-5")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Táº¡m biá»‡t!")
            return
    
    print("\n" + "="*70)
    print("ğŸ“‹ HÆ°á»›ng dáº«n:")
    print("   â€¢ NÃ³i bÃ¬nh thÆ°á»ng, há»‡ thá»‘ng tá»± nháº­n diá»‡n")
    print("   â€¢ Nháº¥n Enter Ä‘á»ƒ dá»«ng Ä‘oáº¡n ghi Ã¢m hiá»‡n táº¡i")
    print("   â€¢ Nháº¥n 'u' + Enter Ä‘á»ƒ cáº­p nháº­t thÃ´ng tin cÃ¡ nhÃ¢n")
    print("   â€¢ Ctrl+C Ä‘á»ƒ thoÃ¡t chÆ°Æ¡ng trÃ¬nh")
    print("="*70)
    
    frames = []
    recording = False
    last_speech_time = None
    
    with sd.InputStream(samplerate=sample_rate,
                       channels=1,
                       dtype='float32',
                       blocksize=block_size,
                       callback=audio_callback):
        
        while True:
            try:
                # Check for Enter key press
                if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
                    user_input = sys.stdin.readline().strip()
                    
                    # Náº¿u user nháº­p 'u' thÃ¬ cáº­p nháº­t user info
                    if user_input.lower() == 'u':
                        print("ğŸ”„ Äang cáº­p nháº­t thÃ´ng tin cÃ¡ nhÃ¢n tá»« user_info.json...")
                        llm.update_user_info()
                        continue
                    
                    if recording:
                        print("\nâ¹ï¸ Dá»«ng ghi Ã¢m hiá»‡n táº¡i.")
                        result = process_audio_with_llm(frames, stt_model, llm,
                                                      hallucination_filter, device,
                                                      sample_rate, selected_topic)
                        if result:
                            stats['successful_responses'] += 1
                        
                        print("-" * 60)
                        frames = []
                        recording = False
                        last_speech_time = None
                    else:
                        print("\nâš ï¸ ChÆ°a cÃ³ Ä‘oáº¡n nÃ o Ä‘ang ghi Ã¢m.")
                        print("ğŸ¤ Tiáº¿p tá»¥c nÃ³i, nháº¥n 'u' Ä‘á»ƒ update user info, hoáº·c nháº¥n Enter...")
                
                audio_block = q.get()
                
                # Noise reduction
                audio_float32 = audio_block.flatten()
                # Sá»¬A Lá»–I: ThÃªm dÃ²ng reduce_noise trÆ°á»›c khi sá»­ dá»¥ng audio_denoised_block
                audio_denoised_block = nr.reduce_noise(y=audio_float32, sr=sample_rate, stationary=False)
                audio_denoised_block = np.nan_to_num(audio_denoised_block, nan=0.0, posinf=0.0, neginf=0.0)
                audio_int16 = (audio_denoised_block * 32768).astype(np.int16)
                
                # VAD check
                speech_detected = is_speech_block(audio_int16, vad_model, sample_rate)
                
                if speech_detected:
                    if not recording:
                        print("\nğŸ¤ PhÃ¡t hiá»‡n tiáº¿ng nÃ³i, báº¯t Ä‘áº§u ghi Ã¢m...")
                        recording = True
                    
                    frames.append(audio_denoised_block)
                    last_speech_time = time.time()
                else:
                    if recording:
                        silence_time = time.time() - last_speech_time
                        if silence_time > silence_threshold:
                            print(f"\nâ¹ï¸ Dá»«ng ghi Ã¢m sau {silence_time:.2f}s im láº·ng.")
                            result = process_audio_with_llm(frames, stt_model, llm,
                                                          hallucination_filter, device,
                                                          sample_rate, selected_topic)
                            if result:
                                stats['successful_responses'] += 1
                            else:
                                stats['filtered_hallucinations'] += 1
                            
                            stats['total_transcriptions'] += 1
                            print(f"ğŸ“Š Stats: {stats['successful_responses']}/{stats['total_transcriptions']} successful")
                            print("-" * 60)
                            
                            frames = []
                            recording = False
                            last_speech_time = None
                            
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng Enhanced Vietnamese Companion Chatbot!")
                print(f"\nğŸ“Š Final Stats:")
                print(f"   Total transcriptions: {stats['total_transcriptions']}")
                print(f"   Successful responses: {stats['successful_responses']}")
                print(f"   Filtered hallucinations: {stats['filtered_hallucinations']}")
                
                if stats['total_transcriptions'] > 0:
                    success_rate = (stats['successful_responses'] / stats['total_transcriptions']) * 100
                    filter_rate = (stats['filtered_hallucinations'] / stats['total_transcriptions']) * 100
                    print(f"   Success rate: {success_rate:.1f}%")
                    print(f"   Filter rate: {filter_rate:.1f}%")
                break
                
            except Exception as e:
                print(f"âŒ Lá»—i: {e}")
                continue

# ==================== MAIN FUNCTION ====================

def main():
    print("=" * 70)
    print("                 ğŸ¤– VIETNAMESE COMPANION CHATBOT")
    print("                            Terminal Mode ")
    # print("   âœ… ÄÃ£ cáº­p nháº­t user_info tá»« file JSON")
    # print("   âœ… Hiá»ƒn thá»‹ thá»i gian xá»­ lÃ½ STT, LLM vÃ  tá»•ng thá»i gian")
    print("=" * 70)
    
    try:
        run_terminal_mode()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Táº¡m biá»‡t!")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")

if __name__ == "__main__":
    main()